{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuestionOrNot: English Text Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal of this project is to build a machine learning model that is able to predict if the given sentence is a question or not. All details can be found in the project report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of the built classifier:\n",
    "\n",
    "Accuracy:  0.7910179640718563\n",
    "Error Rate:  0.20898203592814368\n",
    "Precision:  0.8260572987721692\n",
    "Recall:  0.7321644498186215\n",
    "F1 =  0.7901073177758571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk.data;\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import word2vec;\n",
    "from sklearn.cluster import KMeans;\n",
    "from sklearn.neighbors import KDTree;\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import os;\n",
    "import re;\n",
    "import logging;\n",
    "import sqlite3;\n",
    "import time;\n",
    "import sys;\n",
    "import multiprocessing;\n",
    "import matplotlib.pyplot as plt;\n",
    "from itertools import cycle;\n",
    "import numpy\n",
    "import io\n",
    "import gensim.downloader as api\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('CPCS433Dataset.csv')\n",
    "dataframe.rename(columns = {'sentence ':'sentence'}, inplace = True)\n",
    "\n",
    "#change to lower case\n",
    "dataframe['sentence'] = dataframe['sentence'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>is 3hrill com brandable for a t shirt business...</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>why effective app support is necessary for you...</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>what business can be set up next to a car show...</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>how should i report a vending machine competitor</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>how can i retain younger employees with least ...</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence type\n",
       "0  is 3hrill com brandable for a t shirt business...    Q\n",
       "1  why effective app support is necessary for you...    Q\n",
       "2  what business can be set up next to a car show...    Q\n",
       "3   how should i report a vending machine competitor    Q\n",
       "4  how can i retain younger employees with least ...    Q"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ii a midnight autumns dream is italian power m...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>her disinherited nephew pony duke and jason th...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>in the year 2000 it became an independent club</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>kaleidoscope heart is the third studio album a...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>is facebooks decision to algorithmically selec...</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>what are some mind blowing bike inventions</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>what are some examples of positive effects of ...</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>it took place between indonesias declaration o...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>what can i do to improve my knowledge of thing...</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>other volunteers including tejano and texian c...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence type\n",
       "0  ii a midnight autumns dream is italian power m...    S\n",
       "1  her disinherited nephew pony duke and jason th...    S\n",
       "2     in the year 2000 it became an independent club    S\n",
       "3  kaleidoscope heart is the third studio album a...    S\n",
       "4  is facebooks decision to algorithmically selec...    Q\n",
       "5         what are some mind blowing bike inventions    Q\n",
       "6  what are some examples of positive effects of ...    Q\n",
       "7  it took place between indonesias declaration o...    S\n",
       "8  what can i do to improve my knowledge of thing...    Q\n",
       "9  other volunteers including tejano and texian c...    S"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "dataframe.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The frequency distribution of the words\n",
    "sentences = dataframe.sentence.str.cat(sep=' ')\n",
    "\n",
    "#Tokenize sentences\n",
    "tokens = nltk.word_tokenize(sentences)\n",
    "\n",
    "#Get frequency distribution\n",
    "freqDist = nltk.FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>type</th>\n",
       "      <th>tokenized_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ii a midnight autumns dream is italian power m...</td>\n",
       "      <td>S</td>\n",
       "      <td>[ii, a, midnight, autumns, dream, is, italian,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>her disinherited nephew pony duke and jason th...</td>\n",
       "      <td>S</td>\n",
       "      <td>[her, disinherited, nephew, pony, duke, and, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>in the year 2000 it became an independent club</td>\n",
       "      <td>S</td>\n",
       "      <td>[in, the, year, 2000, it, became, an, independ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>kaleidoscope heart is the third studio album a...</td>\n",
       "      <td>S</td>\n",
       "      <td>[kaleidoscope, heart, is, the, third, studio, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>is facebooks decision to algorithmically selec...</td>\n",
       "      <td>Q</td>\n",
       "      <td>[is, facebooks, decision, to, algorithmically,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence type  \\\n",
       "0  ii a midnight autumns dream is italian power m...    S   \n",
       "1  her disinherited nephew pony duke and jason th...    S   \n",
       "2     in the year 2000 it became an independent club    S   \n",
       "3  kaleidoscope heart is the third studio album a...    S   \n",
       "4  is facebooks decision to algorithmically selec...    Q   \n",
       "\n",
       "                                     tokenized_sents  \n",
       "0  [ii, a, midnight, autumns, dream, is, italian,...  \n",
       "1  [her, disinherited, nephew, pony, duke, and, j...  \n",
       "2  [in, the, year, 2000, it, became, an, independ...  \n",
       "3  [kaleidoscope, heart, is, the, third, studio, ...  \n",
       "4  [is, facebooks, decision, to, algorithmically,...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['tokenized_sents'] = dataframe.apply(lambda row: nltk.word_tokenize(row['sentence']), axis=1)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# download the model and return as object ready for use\n",
    "model_glove_twitter = api.load(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "model_gigaword = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_into_vec(df):\n",
    "  # Iterate over each row\n",
    "  for index, row in df.iterrows():\n",
    "    # Extract cell\n",
    "    sent = row['tokenized_sents']\n",
    "\n",
    "    # Vectorize\n",
    "    try:\n",
    "      vectors = [model_gigaword[x] for x in sent]\n",
    "    except:\n",
    "        \"\"\n",
    "\n",
    "    vec = []\n",
    "    for v in vectors:\n",
    "      vec = np.concatenate((vec, v), axis=0)\n",
    "\n",
    "    # Save vector over cell\n",
    "    row['tokenized_sents'] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>type</th>\n",
       "      <th>tokenized_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ii a midnight autumns dream is italian power m...</td>\n",
       "      <td>S</td>\n",
       "      <td>[-0.08455000072717667, 0.4552899897098541, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>her disinherited nephew pony duke and jason th...</td>\n",
       "      <td>S</td>\n",
       "      <td>[0.33390000462532043, -0.5213599801063538, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>in the year 2000 it became an independent club</td>\n",
       "      <td>S</td>\n",
       "      <td>[0.08570300042629242, -0.22201000154018402, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>kaleidoscope heart is the third studio album a...</td>\n",
       "      <td>S</td>\n",
       "      <td>[0.08570300042629242, -0.22201000154018402, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>is facebooks decision to algorithmically selec...</td>\n",
       "      <td>Q</td>\n",
       "      <td>[0.08570300042629242, -0.22201000154018402, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence type  \\\n",
       "0  ii a midnight autumns dream is italian power m...    S   \n",
       "1  her disinherited nephew pony duke and jason th...    S   \n",
       "2     in the year 2000 it became an independent club    S   \n",
       "3  kaleidoscope heart is the third studio album a...    S   \n",
       "4  is facebooks decision to algorithmically selec...    Q   \n",
       "\n",
       "                                     tokenized_sents  \n",
       "0  [-0.08455000072717667, 0.4552899897098541, -0....  \n",
       "1  [0.33390000462532043, -0.5213599801063538, 0.2...  \n",
       "2  [0.08570300042629242, -0.22201000154018402, 0....  \n",
       "3  [0.08570300042629242, -0.22201000154018402, 0....  \n",
       "4  [0.08570300042629242, -0.22201000154018402, 0....  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorize sentences\n",
    "sentence_into_vec(dataframe)\n",
    "\n",
    "#check vectors\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length:  3900\n"
     ]
    }
   ],
   "source": [
    "#Get maximum length of vectors\n",
    "max_shape = 0\n",
    "for index, row in dataframe.iterrows():\n",
    "    sent = row['tokenized_sents']\n",
    "    current = sent.shape[0]\n",
    "    if current > max_shape:\n",
    "      max_shape = current\n",
    "print(\"Maximum shape: \",max_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Encode label \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "dataframe['type'] = encoder.fit_transform(dataframe['type'])\n",
    "\n",
    "features = dataframe['tokenized_sents']\n",
    "label = dataframe['type']\n",
    "\n",
    "featuresP = pad_sequences(features)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(featuresP, label, train_size=0.8)\n",
    "\n",
    "#Train SVM Model\n",
    "\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(x_train,y_train)\n",
    "predictions_SVM = SVM.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7910179640718563\n",
      "Error Rate:  0.20898203592814368\n",
      "Precision:  0.8260572987721692\n",
      "Recall:  0.7321644498186215\n",
      "F1 =  0.7901073177758571\n",
      "Confusion matrix [[1431  255]\n",
      " [ 443 1211]]\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "acc = accuracy_score(predictions_SVM, y_test)\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Error Rate: \", 1 - acc)\n",
    "print(\"Precision: \", precision_score(y_test, predictions_SVM))\n",
    "print(\"Recall: \", recall_score(y_test, predictions_SVM))\n",
    "print(\"F1 = \", f1_score(y_test, predictions_SVM , average=\"macro\"))\n",
    "print(\"Confusion matrix\", confusion_matrix(y_test, predictions_SVM))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
